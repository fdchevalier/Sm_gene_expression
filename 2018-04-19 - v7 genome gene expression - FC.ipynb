{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-04-19 v7 genome gene expression\n",
    "\n",
    "\n",
    "## Aim\n",
    "\n",
    "Gene expression table can help prioritize candidate gene by selecting only genes expressed in the stage of interest. To generate such expression table, we need RNA-seq data. Several dataset are already publish for a lot of stage. This is the list of dataset I will use:\n",
    "* Eggs from [Anderson *et al.*, 2015](https://doi.org/10.1371/journal.pntd.0004334)\n",
    "* Miracidia from [Wang *et al.*, 2013](https://doi.org/10.7554/eLife.00768.001)\n",
    "* Cercariae, schistosomula 3h and 24h (*in vitro* transformation) from [Protasio *et al.*, 2012](https://doi.org/10.1371/journal.pntd.0001455)\n",
    "* Sporocyst 48h (*in vitro* transformation) from [Wang *et al.*, 2013](https://doi.org/10.7554/eLife.00768.001)\n",
    "* Juveniles (single sex) (18, 21, 28 day old) from [Protasio *et al.*, 2017](https://doi.org/10.1371/journal.pntd.0005559)\n",
    "* Adults (separate males and females from mix infections) [Protasio *et al.*, 2017](https://doi.org/10.1371/journal.pntd.0005559)\n",
    "\n",
    "Data will be aligned against the v7 genome of *S. mansoni*.\n",
    "\n",
    "\n",
    "## Tool preparation\n",
    "\n",
    "STAR will be used to align data and RSEM will be used to generate transcript per million (TPM) counts. These two tools require a step to prepare the reference genome.\n",
    "\n",
    "### STAR reference genome\n",
    "\n",
    "Creating a STAR reference genome requires the use of an annotation file. The Sanger Institute provided us with a GFF file which a format that can be normally used with STAR. However my first attempt to generate a STAR reference genome using the `--sjdbGTFtagExonParentTranscript Parent` option as mentioned in the manual did not allow me to get gene counts after running STAR on sample (the gene count file contains only the first 4 lines). This problem is very similar to [this](https://groups.google.com/forum/#!msg/rna-star/oRvzihFXE8k/Xa-7YgUUBgAJ). Therefore I converted the GFF file into a GTF file which is the default format used by STAR and this solved the problem.\n",
    "\n",
    "Because the data used were generated on different platforms that produced different read sizes, I made two reference genomes using different values for the `--sjdbOverhang` option as recommended in the STAR documentation:\n",
    "* A value of 75 for libraries that have 76 bp paired-end reads (the Protasio *et al* 2012).\n",
    "* A value of 99 for libraries that have 100 bp paired-end reads (all the others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GTF file\n",
    "cd ~/data/sm_Gene_table/\n",
    "gffread Sm_v7.1_renamed.gff -T -o Sm_v7.1_renamed.gtf\n",
    "\n",
    "# Generate ref genome for STAR for 76 and 100 bp paired-end reads as well as pyrosequencing reads\n",
    "## Max read length from pyrosequencing data was obtained after downloading the library.\n",
    "## Here was the command line used (source: https://www.biostars.org/p/304055/#304062):\n",
    "## gunzip -c data/egg/egg_R2.fastq.gz | paste - - - - | awk -F '\\t' '{L=length($2);if(L>M) {M=L;R=$0;}} END {print R;}' | tr \"\\t\" \"\\n\" | h\n",
    "cd ~/data/sm_genome/\n",
    "\n",
    "length=\"75 99 2043\"\n",
    "\n",
    "for i in $length\n",
    "do\n",
    "    # Make ref folder\n",
    "    mkdir Smansoni_v7_renamed_STAR_${i}\n",
    "    cd Smansoni_v7_renamed_STAR_${i}\n",
    "\n",
    "    STAR --runMode genomeGenerate \\\n",
    "         --runThreadN $(nproc)    \\\n",
    "         --genomeDir ~/data/sm_genome/Smansoni_v7_renamed_STAR_${i} \\\n",
    "         --genomeFastaFiles ~/data/sm_genome/Smansoni_v7_renamed.fa \\\n",
    "         --sjdbGTFfile ~/data/sm_Gene_table/Sm_v7.1_renamed.gtf     \\\n",
    "         --sjdbOverhang $i\n",
    "         \n",
    "    cd ..\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### RSEM reference\n",
    "\n",
    "RSEM requires to generate a reference using the GFF and the reference genome file as mentioned in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir=\"~/data/sm_genome/Smansoni_v7_renamed_RSEM\"\n",
    "mkdir $mydir\n",
    "cd $mydir\n",
    "\n",
    "rsem-prepare-reference --gff3 ../../sm_Gene_table/Sm_v7.1_renamed.gff ../Smansoni_v7_renamed.fa Smansoni_v7_renamed > log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project directory\n",
    "mydir=\"$HOME/analyses/00 - Misc/2018-04-19 v7 genome gene expression\"\n",
    "mkdir -p \"$mydir\"\n",
    "cd \"$mydir\"\n",
    "\n",
    "# Data dir\n",
    "mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protasio *et al.*, 2012\n",
    "\n",
    "Data are available from EBI (accession number [E-MTAB-451](https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-451/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the metadata file\n",
    "wget \"https://www.ebi.ac.uk/arrayexpress/files/E-MTAB-451/E-MTAB-451.sdrf.txt\"\n",
    "\n",
    "# EBI Runs\n",
    "myspls=$(cut -f 1 E-MTAB-451.sdrf.txt | tail -n +2 | sort | uniq)\n",
    "\n",
    "for s in $myspls\n",
    "do\n",
    "    mylines=$(awk -F \"\\t\" -v r=$s '$1 == r {print $1\"\\t\"$32}' E-MTAB-451.sdrf.txt)\n",
    "\n",
    "    echo \"$mylines\" | while read line\n",
    "    do\n",
    "        myfile=$(echo \"$line\" cut -f 2 | cut -d \"/\" -f 8 | cut -d \".\" -f 1)\n",
    "        \n",
    "        [[ ! -d \"data/$s\" ]] && mkdir \"data/$s\"\n",
    "        wget -P data/$s/ $(echo \"$line\" | cut -f 2)\n",
    "    done\n",
    "    \n",
    "    if [[ $(echo \"$mylines\" | wc -l) -le 2 ]]\n",
    "    then\n",
    "        mv data/$s/*_1.fastq.gz data/$s/${s}_R1.fastq.gz\n",
    "        mv data/$s/*_2.fastq.gz data/$s/${s}_R2.fastq.gz\n",
    "    else\n",
    "        cat data/$s/*_1.fastq.gz > data/$s/${s}_R1.fastq.gz && rm data/$s/*_1.fastq.gz\n",
    "        cat data/$s/*_2.fastq.gz > data/$s/${s}_R2.fastq.gz && rm data/$s/*_2.fastq.gz\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protasio *et al.*, 2017\n",
    "\n",
    "Data are available on EBI (accession number [E-ERAD-478](https://www.ebi.ac.uk/arrayexpress/experiments/E-ERAD-478/)) but the metadata were not informative enough to know what libraries correspond to a given stage. So I ask directly Anna Protasio who gave me the information (output.csv file). Below the explanation she emailed me:\n",
    "\n",
    ">With Nancy's help, I managed to map the accession numbers to the metadata that we have. Rest assure that we will update these samples in ArrayExpress as soon as we can. \n",
    ">\n",
    ">You will find that all the sequencing files are repeated (NNNNN_3_X). N corresponds to the Illumina sequencing run. Originally, these technology (HiSeq2500 I think) splits each library into two lanes, NNNN_1 and NNNNN_2 but they are the same sample. I tend to merge them into one, hence the _3,  but the submission was still done at the individual (_1 and _2) level. Basically, if you want to analyse these data you can merge both experiments with the same \"Item\" identification. \n",
    ">\n",
    ">One more thing, I seem to be missing  metadata for some of the samples found in the ArrayExpress submission. I reckon these were not used in the analyses and therefore I have no information of what they are at hand. We will dig this up and place it in ArrayExpresss as part of the metadata improvement. In the meantime, I believe all the data that was used (male, female, D18 to D35 post infection, Paired and Unpaired aka virgins) is there. \n",
    "\n",
    "Only paired worms from immature (D21 and 28) and adult stage (D38) will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the metadata file\n",
    "wget \"https://www.ebi.ac.uk/arrayexpress/files/E-ERAD-478/E-ERAD-478.sdrf.txt\"\n",
    "\n",
    "## Load the output.csv file ##\n",
    "\n",
    "# Number of pair and unpaired worm libraries\n",
    "for i in $(cut -d \",\" -f 6 output.csv | sort | uniq)\n",
    "do \n",
    "    mylines=$(awk -F \",\" -v i=$i '$6 == i {print $9}' output.csv)\n",
    "    echo \"$i $(echo \"$mylines\" | grep -c U) $(echo \"$mylines\" | grep -c P)\"\n",
    "done\n",
    "\n",
    "# EBI Runs\n",
    "mystgs=\"D21 D28 D38\"\n",
    "\n",
    "for s in $mystgs\n",
    "do\n",
    "    \n",
    "    mylines=$(awk -F \",\" -v r=$s '$6 == r && $9 == \"P\" {print $0}' output.csv)\n",
    "\n",
    "    echo \"$mylines\" | while read line\n",
    "    do\n",
    "        id=$(echo \"$line\" | cut -d \",\" -f 7)\n",
    "        myrun=$(echo \"$line\" | cut -d \",\" -f 3)\n",
    "        \n",
    "        data_dir=\"data/worms_${s}_${id}\"\n",
    "        \n",
    "        echo \"$data_dir\"\n",
    "        \n",
    "        [[ ! -d \"$data_dir\" ]] && mkdir \"$data_dir\"\n",
    "        fastq-dump -O \"$data_dir\" --split-files --gzip -A $myrun\n",
    "        \n",
    "    done\n",
    "done\n",
    "\n",
    "\n",
    "# Rename fastq\n",
    "for s in $mystgs\n",
    "do\n",
    "    # List directories\n",
    "    mydir=$(find data -maxdepth 1 | grep $s)\n",
    "    \n",
    "    for d in $mydir\n",
    "    do\n",
    "        myname=${d#*/}\n",
    "        if [[ $(ls -1 \"$d\"/*.fastq.gz | wc -l) -le 2 ]]\n",
    "        then\n",
    "            mv $d/*_1.fastq.gz $d/${myname}_R1.fastq.gz\n",
    "            mv $d/*_2.fastq.gz $d/${myname}_R2.fastq.gz\n",
    "        else\n",
    "            cat $d/*_1.fastq.gz > $d/${myname}_R1.fastq.gz && rm $d/*_1.fastq.gz\n",
    "            cat $d/*_2.fastq.gz > $d/${myname}_R2.fastq.gz && rm $d/*_2.fastq.gz\n",
    "        fi\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wang *et al.*, 2013\n",
    "\n",
    "Data are available on [NCBI](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE48282)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run table downloaded from https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=SRP026308 and renamed SraRunTable.Miracidium-Sp.txt\n",
    "\n",
    "while read line\n",
    "do\n",
    "    spl=$(echo \"$line\" | cut -f 8)\n",
    "    acc=$(echo \"$line\" | cut -f 5)\n",
    "    \n",
    "    [[ $spl =~ \"sporocyst\" ]] && spl=\"sporocyst_48h\"\n",
    "    \n",
    "    # Create sample folder\n",
    "    [[ ! -d \"data/$spl\" ]] && mkdir \"data/$spl\"\n",
    "    \n",
    "    # Download from NCBI\n",
    "    fastq-dump -O \"data/$spl\" --split-files --gzip -A $acc\n",
    "    \n",
    "    # Rename files\n",
    "    mv \"data/$spl/\"*_1.fastq.gz \"data/$spl/${spl}_R1.fastq.gz\"\n",
    "    \n",
    "done < <(tail -n +2 SraRunTable.Miracidium-Sp.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anderson *et al.*, 2015\n",
    "\n",
    "Data are available on [NCBI](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA294789)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run table downloaded from https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=SRP063353 and renamed SraRunTable-Anderson2015.txt\n",
    "\n",
    "while read line\n",
    "do\n",
    "    spl=$(echo \"$line\" | cut -f 9)\n",
    "    acc=$(echo \"$line\" | cut -f 7)\n",
    "    \n",
    "    [[ $spl =~ \"egg\" ]] && spl=\"egg\" || continue\n",
    "    \n",
    "    # Create sample folder\n",
    "    [[ ! -d \"data/$spl\" ]] && mkdir \"data/$spl\"\n",
    "    \n",
    "    # Download from NCBI\n",
    "    fastq-dump -O \"data/$spl\" --split-files --gzip -A $acc\n",
    "    \n",
    "    # Rename files\n",
    "    mv \"data/$spl/\"*_1.fastq.gz \"data/$spl/${spl}_R1.fastq.gz\"\n",
    "    mv \"data/$spl/\"*_2.fastq.gz \"data/$spl/${spl}_R2.fastq.gz\"\n",
    "    \n",
    "done < <(tail -n +2 SraRunTable.Anderson2015.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing samples\n",
    "\n",
    "Now that fastq files were downloaded, data will be aligned using STAR and the appropriate reference genome depending on the read length and transcript per million (TPM) will be generated using RSEM.\n",
    "\n",
    "**Note 1**: Egg data has been excluded because generating an error during the alignment steps (`EXITING because of FATAL ERROR in reads input: quality string length is not equal to sequence length`) produced on read 13. Using Trimomatic may solve the problem but was not tested (is Trimomatic good for 454 data?). If e\n",
    "\n",
    "**Note 2**: I had trouble on medusa2 server to run RSEM on nodes because of perl library matching problem. Therefore I run the loop on titan server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# List samples\n",
    "#myspl=(\"egg\" \\\n",
    "myspl=(\"miracidia\"     \\\n",
    "       \"sporocyst_48h\" \\\n",
    "       \"cerc10a cerc12 cerc13\" \\\n",
    "       \"somule1 somule2\"       \\\n",
    "       \"somule3 somule4 somule5 somule6\" \\\n",
    "       \"worms_D21_P1F worms_D21_P2F worms_D21_P3F worms_D21_P5F\" \\\n",
    "       \"worms_D21_P1M worms_D21_P2M worms_D21_P3M worms_D21_P5M\" \\\n",
    "       \"worms_D28_P1F worms_D28_P3F worms_D28_P4F worms_D28_P5F\" \\\n",
    "       \"worms_D28_P1M worms_D28_P3M worms_D28_P4M worms_D28_P5M\" \\\n",
    "       \"worms_D38_P1F worms_D38_P2F worms_D38_P45F\" \\\n",
    "       \"worms_D38_P1M worms_D38_P2M worms_D38_P45M\")\n",
    "\n",
    "# List sample types\n",
    "#mytyp=(egg \\\n",
    "mytyp=(miracidia   \\\n",
    "       sporocyst_48h \\\n",
    "       cercariae   \\\n",
    "       somule_3h   \\\n",
    "       somule_24h  \\\n",
    "       adult_m_21d \\\n",
    "       adult_f_21d \\\n",
    "       adult_m_28d \\\n",
    "       adult_f_28d \\\n",
    "       adult_m_38d \\\n",
    "       adult_f_38d)\n",
    "\n",
    "# List library read length\n",
    "#myrl=(657 100 100 76 76 76 100 100 100 100 100 100)\n",
    "myrl=(100 100 76 76 76 100 100 100 100 100 100)\n",
    "\n",
    "# List paired-end status\n",
    "#myps=(single single single paired paired paired paired paired paired paired paired paired)\n",
    "myps=(single single paired paired paired paired paired paired paired paired paired)\n",
    "\n",
    "\n",
    "# Prepare folders and links\n",
    "for ((i=0 ; i<${#mytyp[@]} ; i++))\n",
    "do\n",
    "    mkdir -p alignment/${mytyp[i]}\n",
    "\n",
    "    \n",
    "    [[ $(echo ${myspl[i]} | wc -w) > 1 ]] && myfd=\"{$(echo ${myspl[i]} | sed s\"/ /,/g\")}\" || myfd=${myspl[i]}\n",
    "    \n",
    "    eval ln -s $(printf '%q' \"$PWD\")/data/$myfd/*fastq.gz $(printf '%q' \"$PWD\")/alignment/${mytyp[i]}/\n",
    "\n",
    "done\n",
    "\n",
    "## Remove one link manually because the reads seems to correspond to tags\n",
    "#rm alignment/egg/egg_R1.fastq.gz\n",
    "\n",
    "\n",
    "# Run STAR on samples\n",
    "ssh medusa2\n",
    "\n",
    "[[ ! -d status ]] && mkdir status\n",
    "\n",
    "# Run the alignment for each sample\n",
    "for ((i=0 ; i<${#mytyp[@]} ; i++))\n",
    "do\n",
    "    tag=$(( ${myrl[i]} -1 ))\n",
    "    d=alignment/${mytyp[i]}\n",
    "    qsub -V -cwd -o status/ -j y -r y -b yes   \\\n",
    "        ~/local/bin/STAR --runMode alignReads  \\\n",
    "                         --runThreadN $(nproc) \\\n",
    "                         --genomeDir ~/data/sm_genome/Smansoni_v7_renamed_STAR_$tag \\\n",
    "                         --readFilesIn $(ls -1 $d/*_{R,}1.fastq.gz 2> /dev/null | tr \"\\n\" \",\" | sed \"s/,$//\") $(ls -1 $d/*_{R,}2.fastq.gz 2> /dev/null | tr \"\\n\" \",\" | sed \"s/,$//\") \\\n",
    "                         --readFilesCommand zcat             \\\n",
    "                         --outFileNamePrefix $d/${d##*/}_    \\\n",
    "                         --outSAMtype BAM SortedByCoordinate \\\n",
    "                         --quantMode TranscriptomeSAM GeneCounts\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "## Wait until jobs done ##\n",
    "\n",
    "# Run RSEM for quantification\n",
    "for ((i=0 ; i<${#mytyp[@]} ; i++))\n",
    "do\n",
    "    # Working folder \n",
    "    d=alignment/${mytyp[i]}\n",
    "    \n",
    "    # Library type for activating RSEM option\n",
    "    [[ ${myps[i]} == single ]] && lib_type=\"\" || lib_type=\"--paired-end\"\n",
    "    \n",
    "    # RSEM process\n",
    "    qsub -V -cwd -o status/ -j y -r y -b yes \\\n",
    "        ~/local/bin/rsem-calculate-expression --alignments $lib_type -p $(nproc) --no-bam-output\\\n",
    "                $d/${d##*/}_Aligned.toTranscriptome.out.bam \\\n",
    "                ~/data/sm_genome/Smansoni_v7_renamed_RSEM/Smansoni_v7_renamed \\\n",
    "                $d/${d##*/}_rsem\n",
    "done\n",
    "\n",
    "## Wait until jobs done ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the jobs done, isoform TPM files are availble for each stage of interest. The final step consists in concatenating this data in a single table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Generate table\n",
    "final_tb=TPM_isoforms_Sm_v7.1.tsv\n",
    "cut -f 1,6 alignment/${mytyp[0]}/${mytyp[0]}_rsem.isoforms.results > \"$final_tb\"\n",
    "\n",
    "for ((i=1 ; i<${#mytyp[@]} ; i++))\n",
    "do\n",
    "    join \"$final_tb\" <(cut -f 1,6 alignment/${mytyp[i]}/${mytyp[i]}_rsem.isoforms.results) > \"${final_tb}.tmp\"\n",
    "    mv \"${final_tb}.tmp\" \"${final_tb}\"\n",
    "done\n",
    "\n",
    "sed -i \"1 s/ .*/ $(echo ${mytyp[@]})/g ; s/ /\\t/g\" \"${final_tb}\"\n",
    "\n",
    "\n",
    "# Link the table to the global data directory\n",
    "ln -s \"$PWD/${final_tb}\" ~/data/sm_Gene_table/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
